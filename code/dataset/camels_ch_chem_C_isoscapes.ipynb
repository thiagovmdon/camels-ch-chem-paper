{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa5eee1",
   "metadata": {},
   "source": [
    "# Isoscape dataset extraction\n",
    "\n",
    "Author: Martina Kauzlaric (martina.kauzlaric@unibe.ch)\n",
    "\n",
    "This notebook is used to extract data from monthly isoscapes (i.e. isotopic landscapes, which are spatially continuous and georeferenced isotope datasets) of deuterium [‚Ä∞] and oxygen-18 [‚Ä∞] with a resolution of 500m provided by the FOEN into a table for publication alongisde the used data.\n",
    "Stable isotope data in precipitation of the isotope observation network in Switzerland (ISOT), together with several influencing variables (e.g., topographical parameters, climate variables) are used in a multi-regression framework, and the residuals are interpolated by the use of ordinary kriging.\n",
    "Monthly data are available for the years between 2007 and 2023.\n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python=3.13.2\n",
    "* Jupyter\n",
    "* os\n",
    "* numpy=2.2.4\n",
    "* xarray=2024.11.0\n",
    "* pandas=2.2.3\n",
    "* geopandas=1.0.1\n",
    "* cartopy=0.24.1\n",
    "* matplotlib=3.10.0\n",
    "* tqdm=4.67.1\n",
    "\n",
    "Check the Github repository for an environment_landcover.yml (for conda environments) file [for semplicity we use the same environment and that used for extracting the landcover data]\n",
    "\n",
    "**Files:**\n",
    "\n",
    "Monthly rasters, e.g.\n",
    "* iso_sum_ras_simple_GEO+N_2H_20070115.asc\n",
    "* iso_sum_ras_simple_GEO+N_18O_20070115.asc\n",
    "\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "* Bundesamt f√ºr Umwelt BAFU\n",
    "* Office f√©d√©ral de l'environnement OFEV\n",
    "* Ufficio federale dell'ambiente UFAM\n",
    "* Federal Office for the Environment FOEN\n",
    "* ¬© BAFU\n",
    "* https://www.bafu.admin.ch/bafu/en/home/topics/water/groundwater/groundwater-resources/stable-water-isotopes.html\n",
    "* https://www.bafu.admin.ch/dam/bafu/de/dokumente/hydrologie/externe-studien-berichte/isoscapes_schweiz_endbericht.pdf.download.pdf/isoscapes_schweiz_endbericht.pdf\n",
    "## Observations\n",
    "* Data are only available for catchments inside the national boundaries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc37bc",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0356cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all variables\n",
    "%reset -f\n",
    "#Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "#import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import MultiPolygon\n",
    "from shapely.geometry import box\n",
    "import tqdm as tqdm\n",
    "import re\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from concurrent.futures import ThreadPoolExecutor # this is to run functions in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c2972",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Set (relative) path to your local directory\n",
    "#PATH = \"../..\"\n",
    "PATH = \"S:\\\\CAMELS-CH\\\\CAMELS-chem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f10adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set directories\n",
    "GIS_dir = os.path.join(PATH,\"data\\\\GIS\")\n",
    "# Define shapefile with the catchments\n",
    "catchments_shp = os.path.join(GIS_dir,\"shapefile_catchments\\\\camels_ch_chem_catchment_boundaries.shp\")\n",
    "#Add subfolder to GIS_dir for Isoscape data\n",
    "GIS_dir = os.path.join(GIS_dir, \"Isoscapes\")  \n",
    "PATH_OUTPUT = os.path.join(PATH,\"results\\\\catchment_aggregated_data\\\\isoscapes\")\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.isdir(PATH_OUTPUT):\n",
    "    os.makedirs(PATH_OUTPUT, exist_ok=True)\n",
    "\n",
    "##Change to directory to where you want to store the results    \n",
    "os.chdir(PATH_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14aa5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nascimth\\\\OneDrive - Eawag\\\\Eawag\\\\Papers\\\\CAMELS_CH_Chem\\\\GitHub\\\\camels-ch-chem-paper\\\\code\\\\dataset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073678d",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e63e6",
   "metadata": {},
   "source": [
    "# Import data\n",
    "* Load catchments and look at full table\n",
    "\n",
    "*Note: data are in LV95/CH1903+, i.e. EPSG 2056*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74cbf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>nawaf_id</th>\n",
       "      <th>nawat_id</th>\n",
       "      <th>isot_id</th>\n",
       "      <th>chirp_id</th>\n",
       "      <th>gauge_name</th>\n",
       "      <th>water_body</th>\n",
       "      <th>gauge_east</th>\n",
       "      <th>gauge_nort</th>\n",
       "      <th>gauge_lon</th>\n",
       "      <th>gauge_lat</th>\n",
       "      <th>area</th>\n",
       "      <th>area_swiss</th>\n",
       "      <th>geometry</th>\n",
       "      <th>bafu_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>NIO04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porte du Scex</td>\n",
       "      <td>Rh√¥ne</td>\n",
       "      <td>557660</td>\n",
       "      <td>133280</td>\n",
       "      <td>6.89</td>\n",
       "      <td>46.35</td>\n",
       "      <td>5239.4</td>\n",
       "      <td>99.994914</td>\n",
       "      <td>POLYGON Z ((2674253.038 1167429.881 0, 2674340...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sion</td>\n",
       "      <td>Rh√¥ne</td>\n",
       "      <td>593770</td>\n",
       "      <td>118630</td>\n",
       "      <td>7.36</td>\n",
       "      <td>46.22</td>\n",
       "      <td>3372.4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2674253.038 1167429.881 0, 2674340...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>NIO02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brugg</td>\n",
       "      <td>Aare</td>\n",
       "      <td>657000</td>\n",
       "      <td>259360</td>\n",
       "      <td>8.19</td>\n",
       "      <td>47.48</td>\n",
       "      <td>11681.3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2655969.68 1259695.589 0, 2655976....</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mellingen</td>\n",
       "      <td>Reuss</td>\n",
       "      <td>662830</td>\n",
       "      <td>252580</td>\n",
       "      <td>8.27</td>\n",
       "      <td>47.42</td>\n",
       "      <td>3385.8</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2663723.38 1252919.068 0, 2663794....</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>NIO01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brienzwiler</td>\n",
       "      <td>Aare</td>\n",
       "      <td>649930</td>\n",
       "      <td>177380</td>\n",
       "      <td>8.09</td>\n",
       "      <td>46.75</td>\n",
       "      <td>555.2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2669196.412 1183579.51 0, 2669203....</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2617</td>\n",
       "      <td>2617.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M√ºstair</td>\n",
       "      <td>Rom</td>\n",
       "      <td>830800</td>\n",
       "      <td>168700</td>\n",
       "      <td>10.45</td>\n",
       "      <td>46.63</td>\n",
       "      <td>128.6</td>\n",
       "      <td>42.552175</td>\n",
       "      <td>POLYGON Z ((2820942.826 1171469.984 0, 2820953...</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2623</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oberwald</td>\n",
       "      <td>Rhone</td>\n",
       "      <td>669900</td>\n",
       "      <td>154075</td>\n",
       "      <td>8.35</td>\n",
       "      <td>46.53</td>\n",
       "      <td>93.3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2674253.038 1167429.881 0, 2674340...</td>\n",
       "      <td>2623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2634</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>6169.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emmen</td>\n",
       "      <td>Kleine Emme</td>\n",
       "      <td>663700</td>\n",
       "      <td>213630</td>\n",
       "      <td>8.28</td>\n",
       "      <td>47.07</td>\n",
       "      <td>478.3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2653429.237 1216261.807 0, 2653439...</td>\n",
       "      <td>2634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2635</td>\n",
       "      <td>2635.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Einsiedeln, Gross</td>\n",
       "      <td>Grossbach</td>\n",
       "      <td>700710</td>\n",
       "      <td>218125</td>\n",
       "      <td>8.77</td>\n",
       "      <td>47.11</td>\n",
       "      <td>8.9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2701144.527 1218073.633 0, 2701261...</td>\n",
       "      <td>2635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Del√©mont, Pr√©-Guillaume</td>\n",
       "      <td>Sorne</td>\n",
       "      <td>593380</td>\n",
       "      <td>245940</td>\n",
       "      <td>7.35</td>\n",
       "      <td>47.36</td>\n",
       "      <td>213.9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>POLYGON Z ((2584725.396 1248420.902 0, 2584728...</td>\n",
       "      <td>2640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gauge_id  sensor_id  nawaf_id  nawat_id isot_id  chirp_id  \\\n",
       "0        2009     2009.0    1837.0    1837.0   NIO04       NaN   \n",
       "1        2011     2011.0       NaN    4070.0    None       NaN   \n",
       "2        2016     2016.0    1833.0    1833.0   NIO02       NaN   \n",
       "3        2018     2018.0    1835.0    1339.0    None       NaN   \n",
       "4        2019     2019.0       NaN    1852.0   NIO01       NaN   \n",
       "..        ...        ...       ...       ...     ...       ...   \n",
       "110      2617     2617.0       NaN       NaN    None       NaN   \n",
       "111      2623     2623.0       NaN       NaN    None       NaN   \n",
       "112      2634     2634.0    6169.0    1181.0    None       NaN   \n",
       "113      2635     2635.0       NaN       NaN    None       NaN   \n",
       "114      2640        NaN       NaN    1504.0    None       NaN   \n",
       "\n",
       "                  gauge_name   water_body  gauge_east  gauge_nort  gauge_lon  \\\n",
       "0              Porte du Scex        Rh√¥ne      557660      133280       6.89   \n",
       "1                       Sion        Rh√¥ne      593770      118630       7.36   \n",
       "2                      Brugg         Aare      657000      259360       8.19   \n",
       "3                  Mellingen        Reuss      662830      252580       8.27   \n",
       "4                Brienzwiler         Aare      649930      177380       8.09   \n",
       "..                       ...          ...         ...         ...        ...   \n",
       "110                  M√ºstair          Rom      830800      168700      10.45   \n",
       "111                 Oberwald        Rhone      669900      154075       8.35   \n",
       "112                    Emmen  Kleine Emme      663700      213630       8.28   \n",
       "113        Einsiedeln, Gross    Grossbach      700710      218125       8.77   \n",
       "114  Del√©mont, Pr√©-Guillaume        Sorne      593380      245940       7.35   \n",
       "\n",
       "     gauge_lat     area  area_swiss  \\\n",
       "0        46.35   5239.4   99.994914   \n",
       "1        46.22   3372.4  100.000000   \n",
       "2        47.48  11681.3  100.000000   \n",
       "3        47.42   3385.8  100.000000   \n",
       "4        46.75    555.2  100.000000   \n",
       "..         ...      ...         ...   \n",
       "110      46.63    128.6   42.552175   \n",
       "111      46.53     93.3  100.000000   \n",
       "112      47.07    478.3  100.000000   \n",
       "113      47.11      8.9  100.000000   \n",
       "114      47.36    213.9  100.000000   \n",
       "\n",
       "                                              geometry  bafu_id  \n",
       "0    POLYGON Z ((2674253.038 1167429.881 0, 2674340...     2009  \n",
       "1    POLYGON Z ((2674253.038 1167429.881 0, 2674340...     2011  \n",
       "2    POLYGON Z ((2655969.68 1259695.589 0, 2655976....     2016  \n",
       "3    POLYGON Z ((2663723.38 1252919.068 0, 2663794....     2018  \n",
       "4    POLYGON Z ((2669196.412 1183579.51 0, 2669203....     2019  \n",
       "..                                                 ...      ...  \n",
       "110  POLYGON Z ((2820942.826 1171469.984 0, 2820953...     2617  \n",
       "111  POLYGON Z ((2674253.038 1167429.881 0, 2674340...     2623  \n",
       "112  POLYGON Z ((2653429.237 1216261.807 0, 2653439...     2634  \n",
       "113  POLYGON Z ((2701144.527 1218073.633 0, 2701261...     2635  \n",
       "114  POLYGON Z ((2584725.396 1248420.902 0, 2584728...     2640  \n",
       "\n",
       "[115 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catchments = gpd.read_file(catchments_shp)\n",
    "catchments[\"bafu_id\"] = catchments[\"gauge_id\"]\n",
    "catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f779e",
   "metadata": {},
   "source": [
    "Now we get the isoscapes and extract these per catchment.\n",
    "\n",
    "*Note: data are in LV95/CH1903+, i.e. EPSG 2056*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c22a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18O_Monatsraster_2007_2023', '2H_Monatsraster_2007_2023']\n"
     ]
    }
   ],
   "source": [
    "# Detect directories containing monthly isoscape data\n",
    "ascii_dirs = [d for d in os.listdir(GIS_dir) if \"Monatsraster\" in d]\n",
    "print(ascii_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3627d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define isotopes to be extracted\n",
    "isotopes = [\"18O\", \"2H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9245d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTION FOR ONE CATCHMENT ---\n",
    "def process_catchment(args):\n",
    "    catch_idx, catch, raster_files, isotope, crs, isotope_outdir = args\n",
    "\n",
    "    catch_id = catch[\"gauge_id\"]\n",
    "    catch_geom = gpd.GeoDataFrame([catch], crs=crs)\n",
    "\n",
    "    values = []\n",
    "    months = []\n",
    "\n",
    "    for file_path in raster_files:\n",
    "        month_match = re.search(r\"_(\\d{8})\\.asc$\", file_path)\n",
    "        if not month_match:\n",
    "            continue\n",
    "        date_str = month_match.group(1)\n",
    "        date = pd.to_datetime(date_str, format=\"%Y%m%d\")\n",
    "        months.append(date)\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(file_path) as src:\n",
    "                out_image, _ = mask(src, catch_geom.geometry, crop=True)\n",
    "                out_image = out_image[0]\n",
    "                valid = out_image != src.nodata\n",
    "                if np.any(valid):\n",
    "                    mean_value = float(np.nanmean(out_image[valid]))\n",
    "                else:\n",
    "                    mean_value = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error in file {file_path} for {catch_id}: {e}\")\n",
    "            mean_value = np.nan\n",
    "\n",
    "        values.append(mean_value)\n",
    "\n",
    "    # Save timeseries\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": months,\n",
    "        f\"{isotope}_monthlymean\": values\n",
    "    })\n",
    "    df.to_csv(os.path.join(isotope_outdir, f\"{catch_id}_isoscape.csv\"),\n",
    "              index=False, sep=\";\", float_format=\"%.2f\")\n",
    "    return catch_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe851291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Processing isotope 18O...\n",
      "üöÄ Launching parallel processing on 20 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catchments for 18O:   0%|          | 0/115 [00:00<?, ?it/s]p:\\Hydrologie\\AnacondaMartina\\envs\\env_CAMELS_CH-chem\\Lib\\site-packages\\rasterio\\features.py:392: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _rasterize(valid_shapes, out, transform, all_touched, merge_alg)\n",
      "p:\\Hydrologie\\AnacondaMartina\\envs\\env_CAMELS_CH-chem\\Lib\\site-packages\\rasterio\\features.py:392: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _rasterize(valid_shapes, out, transform, all_touched, merge_alg)\n",
      "Catchments for 18O: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 115/115 [13:18<00:00,  6.94s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with isotope 18O ‚Äî 115 catchments processed.\n",
      "\n",
      "üß™ Processing isotope 2H...\n",
      "üöÄ Launching parallel processing on 20 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catchments for 2H:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 52/115 [08:54<04:43,  4.50s/it]  p:\\Hydrologie\\AnacondaMartina\\envs\\env_CAMELS_CH-chem\\Lib\\site-packages\\rasterio\\features.py:392: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  _rasterize(valid_shapes, out, transform, all_touched, merge_alg)\n",
      "Catchments for 2H: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 115/115 [13:25<00:00,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with isotope 2H ‚Äî 115 catchments processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN LOOP ---\n",
    "if __name__ == \"__main__\":\n",
    "    for isotope in isotopes:\n",
    "        print(f\"\\nüß™ Processing isotope {isotope}...\")\n",
    "\n",
    "        dir_match = [d for d in ascii_dirs if isotope in d]\n",
    "        if not dir_match:\n",
    "            print(f\"‚ö†Ô∏è No directory found for isotope {isotope}\")\n",
    "            continue\n",
    "\n",
    "        ascii_dir = os.path.join(GIS_dir, dir_match[0])\n",
    "        raster_files = sorted([\n",
    "            os.path.join(ascii_dir, f) for f in os.listdir(ascii_dir) if f.endswith(\".asc\")\n",
    "        ])\n",
    "\n",
    "        isotope_outdir = os.path.join(PATH_OUTPUT, isotope)\n",
    "        os.makedirs(isotope_outdir, exist_ok=True)\n",
    "\n",
    "        task_args = [\n",
    "            (idx, row, raster_files, isotope, catchments.crs, isotope_outdir)\n",
    "            for idx, row in catchments.iterrows()\n",
    "        ]\n",
    "\n",
    "        print(f\"üöÄ Launching parallel processing on {min(20, os.cpu_count())} cores...\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            results = list(tqdm.tqdm(executor.map(process_catchment, task_args),\n",
    "                                     total=len(task_args), desc=f\"Catchments for {isotope}\"))\n",
    "\n",
    "        print(f\"Done with isotope {isotope} ‚Äî {len(results)} catchments processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ec3cc",
   "metadata": {},
   "source": [
    "Here  following is the code to loop over one catchment per time [depending on the number of catchments and the number of cores available maybe necessary..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function ---\n",
    "def extract_mean_per_catchment(raster_fp, catchment_geom):\n",
    "    \"\"\"Returns the mean of raster values within a catchment geometry.\"\"\"\n",
    "    with rasterio.open(raster_fp) as src:\n",
    "        out_image, out_transform = mask(src, catchment_geom.geometry, crop=True)\n",
    "        out_image = out_image[0]  # First band\n",
    "\n",
    "        # Masked values are set to src.nodata\n",
    "        valid = out_image != src.nodata\n",
    "        if np.any(valid):\n",
    "            return float(np.nanmean(out_image[valid]))\n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832a3c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Processing isotope 18O...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catchments for 18O:  10%|‚ñâ         | 11/115 [09:57<1:34:09, 54.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date_str, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     months\u001b[38;5;241m.\u001b[39mappend(date)\n\u001b[1;32m---> 34\u001b[0m     mean_value \u001b[38;5;241m=\u001b[39m extract_mean_per_catchment(file_path, catch_geom)\n\u001b[0;32m     35\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(mean_value)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Save timeseries for this catchment\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m, in \u001b[0;36mextract_mean_per_catchment\u001b[1;34m(raster_fp, catchment_geom)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the mean of raster values within a catchment geometry.\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(raster_fp) \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[1;32m----> 5\u001b[0m     out_image, out_transform \u001b[38;5;241m=\u001b[39m mask(src, catchment_geom\u001b[38;5;241m.\u001b[39mgeometry, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     out_image \u001b[38;5;241m=\u001b[39m out_image[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# First band\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Masked values are set to src.nodata\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Hydrologie\\AnacondaMartina\\envs\\env_CAMELS_CH-chem\\Lib\\site-packages\\rasterio\\mask.py:191\u001b[0m, in \u001b[0;36mmask\u001b[1;34m(dataset, shapes, all_touched, invert, nodata, filled, crop, pad, pad_width, indexes)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     out_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(indexes), ) \u001b[38;5;241m+\u001b[39m shape_mask\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 191\u001b[0m out_image \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    192\u001b[0m     window\u001b[38;5;241m=\u001b[39mwindow, out_shape\u001b[38;5;241m=\u001b[39mout_shape, masked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, indexes\u001b[38;5;241m=\u001b[39mindexes)\n\u001b[0;32m    194\u001b[0m out_image\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m out_image\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m|\u001b[39m shape_mask\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filled:\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:644\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:969\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase._read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\\\_io.pyx:199\u001b[0m, in \u001b[0;36mrasterio._io.io_multi_band\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mp:\\Hydrologie\\AnacondaMartina\\envs\\env_CAMELS_CH-chem\\Lib\\contextlib.py:145\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, typ, value, traceback):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for isotope in isotopes:\n",
    "    print(f\"\\nüß™ Processing isotope {isotope}...\")\n",
    "\n",
    "    # Find the correct directory for this isotope\n",
    "    dir_match = [d for d in ascii_dirs if isotope in d]\n",
    "    if not dir_match:\n",
    "        print(f\"‚ö†Ô∏è No directory found for isotope {isotope}\")\n",
    "        continue\n",
    "\n",
    "    ascii_dir = os.path.join(GIS_dir, dir_match[0])\n",
    "    raster_files = sorted([os.path.join(ascii_dir, f) for f in os.listdir(ascii_dir) if f.endswith(\".asc\")])\n",
    "\n",
    "    # Create output folder for this isotope\n",
    "    isotope_outdir = os.path.join(PATH_OUTPUT, isotope)\n",
    "    os.makedirs(isotope_outdir, exist_ok=True)\n",
    "\n",
    "    # Loop over catchments\n",
    "    for _, catch in tqdm.tqdm(catchments.iterrows(), total=len(catchments), desc=f\"Catchments for {isotope}\"):\n",
    "        catch_id = catch[\"gauge_id\"]\n",
    "        catch_geom = gpd.GeoDataFrame([catch], crs=catchments.crs)\n",
    "\n",
    "        values = []\n",
    "        months = []\n",
    "\n",
    "        for file_path in raster_files:\n",
    "            # Extract date from filename\n",
    "            month_match = re.search(r\"_(\\d{8})\\.asc$\", file_path)\n",
    "            if not month_match:\n",
    "                continue\n",
    "            date_str = month_match.group(1)\n",
    "            date = pd.to_datetime(date_str, format=\"%Y%m%d\")\n",
    "            months.append(date)\n",
    "\n",
    "            mean_value = extract_mean_per_catchment(file_path, catch_geom)\n",
    "            values.append(mean_value)\n",
    "\n",
    "        # Save timeseries for this catchment\n",
    "        df = pd.DataFrame({\n",
    "            \"date\": months,\n",
    "            f\"{isotope}_monthlymean\": values\n",
    "        })\n",
    "        df.to_csv(os.path.join(isotope_outdir, f\"{catch_id}_isoscape.csv\"),\n",
    "                  index=False, sep=\";\", float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439bf43",
   "metadata": {},
   "source": [
    "Eventually, we generate the yearly mean isoscapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0239510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Generating yearly summary for 18O...\n",
      "Saved yearly summary to: S:\\CAMELS-CH\\CAMELS-chem\\results\\catchment_aggregated_data\\isoscapes\\18O_isoscape_yearly_summary.csv\n",
      "\n",
      "üìà Generating yearly summary for 2H...\n",
      "Saved yearly summary to: S:\\CAMELS-CH\\CAMELS-chem\\results\\catchment_aggregated_data\\isoscapes\\2H_isoscape_yearly_summary.csv\n"
     ]
    }
   ],
   "source": [
    "for isotope in isotopes:\n",
    "    print(f\"\\nüìà Generating yearly summary for {isotope}...\")\n",
    "\n",
    "    # Directory with catchment time series for this isotope\n",
    "    iso_dir = os.path.join(PATH_OUTPUT, isotope)\n",
    "    files = [f for f in os.listdir(iso_dir) if f.endswith(\"_isoscape.csv\")]\n",
    "\n",
    "    # Preallocate result DataFrame\n",
    "    yearly_data = {}\n",
    "\n",
    "    for file in files:\n",
    "        catch_id = file.replace(\"_isoscape.csv\", \"\")\n",
    "        filepath = os.path.join(iso_dir, file)\n",
    "\n",
    "        df = pd.read_csv(filepath, sep=\";\", parse_dates=[\"date\"])\n",
    "        df[\"year\"] = df[\"date\"].dt.year\n",
    "\n",
    "        # Column is like \"18O_monthlymean\" or \"2H_monthlymean\"\n",
    "        val_col = [col for col in df.columns if col.endswith(\"_monthlymean\")][0]\n",
    "\n",
    "        yearly_mean = df.groupby(\"year\")[val_col].mean()\n",
    "        yearly_data[catch_id] = yearly_mean\n",
    "\n",
    "    # Combine into one DataFrame (rows = years, columns = catchments)\n",
    "    yearly_df = pd.DataFrame(yearly_data)\n",
    "    yearly_df.index.name = \"year\"\n",
    "\n",
    "    # Save to CSV\n",
    "    out_fp = os.path.join(PATH_OUTPUT, f\"{isotope}_isoscape_yearly_summary.csv\")\n",
    "    yearly_df.to_csv(out_fp, sep=\";\", float_format=\"%.2f\")\n",
    "\n",
    "    print(f\"Saved yearly summary to: {out_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45aa00",
   "metadata": {},
   "source": [
    "Organize the data as time-series for the dataset (stored at the results folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_2h = '../../results/isoscapes/2H'\n",
    "folder_18o = '../../results/isoscapes/18O'\n",
    "output_folder = \"../../results/Dataset/catchment_aggregated_data/rain_water_isotopes\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all files in the 2H folder\n",
    "files_2h = sorted([f for f in os.listdir(folder_2h) if f.endswith('.csv')])\n",
    "\n",
    "for filename in files_2h:\n",
    "    path_2h = os.path.join(folder_2h, filename)\n",
    "    path_18o = os.path.join(folder_18o, filename)\n",
    "\n",
    "    # Read both files\n",
    "    df_2h = pd.read_csv(path_2h, sep=';', parse_dates=['date'])\n",
    "    df_18o = pd.read_csv(path_18o, sep=';', parse_dates=['date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df_2h.rename(columns={'2H_monthlymean': 'delta_2h'}, inplace=True)\n",
    "    df_18o.rename(columns={'18O_monthlymean': 'delta_18o'}, inplace=True)\n",
    "\n",
    "    # Merge on date\n",
    "    df_merged = pd.merge(df_2h, df_18o, on='date')\n",
    "\n",
    "    # Set index\n",
    "    df_merged.set_index('date', inplace=True)\n",
    "    df_merged = df_merged.loc[:\"2020\", :]\n",
    "    # Save the output\n",
    "    output_path = os.path.join(output_folder, f\"camels_ch_chem_rainisotopes_{filename[0:4]}.csv\")\n",
    "    df_merged.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
